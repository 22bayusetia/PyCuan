{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q contractions scikit-learn Sastrawi googletrans==4.0.0-rc1 langdetect pandas matplotlib yfinance tensorflow xgboost\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Va5pdk6Jkuyu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input Data**"
      ],
      "metadata": {
        "id": "PpSjGtmztFqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Revision of Subsidized Fertilizer Policy, Now Farmers Can Redeem Using KTP\""
      ],
      "metadata": {
        "id": "x22azTNLs3LN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZwLtTmQkmdG",
        "outputId": "1b44b48a-90f1-43a7-d895-49cba973830a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: Revision of Subsidized Fertilizer Policy, Now Farmers Can Redeem Using KTP\n",
            "Sentiment Probability: 0.66\n",
            "Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import unicodedata\n",
        "from googletrans import Translator\n",
        "import contractions\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "# Fungsi-fungsi pra-pemrosesan teks\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    [s.extract() for s in soup(['iframe', 'script'])]\n",
        "    stripped_text = soup.get_text()\n",
        "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "    return stripped_text\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "def pre_process_text(text, language):\n",
        "    text = text.lower()\n",
        "    text = strip_html_tags(text)\n",
        "    text = text.translate(text.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    text = remove_accented_chars(text)\n",
        "    text = contractions.fix(text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text, re.I | re.A)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    if language == 'indonesian':\n",
        "        text = preprocess_text_sastrawi(text)\n",
        "    return text\n",
        "\n",
        "# Fungsi pra-pemrosesan teks khusus Bahasa Indonesia\n",
        "def preprocess_text_sastrawi(text):\n",
        "    factory1 = StopWordRemoverFactory()\n",
        "    stopword_sastrawi = factory1.create_stop_word_remover()\n",
        "\n",
        "    factory2 = StemmerFactory()\n",
        "    stemmer_sastrawi = factory2.create_stemmer()\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [stopword_sastrawi.remove(token) for token in tokens]\n",
        "    tokens = [stemmer_sastrawi.stem(token) for token in tokens if token != '']\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Load the models\n",
        "tfidf_vectorizer = joblib.load('/content/tfidf_vectorizer.joblib')\n",
        "rf_classifier = joblib.load('/content/random_forest_model.joblib')\n",
        "\n",
        "# Preprocess the new text\n",
        "preprocessed_text = pre_process_text(new_text, 'indonesian')\n",
        "\n",
        "# Mengonversi teks yang telah di-preprocess menjadi fitur TF-IDF\n",
        "new_text_tfidf = tfidf_vectorizer.transform([preprocessed_text])\n",
        "\n",
        "# Melakukan prediksi sentimen menggunakan model Random Forest\n",
        "predicted_label = rf_classifier.predict(new_text_tfidf)\n",
        "\n",
        "translator = Translator()\n",
        "translated_text = translator.translate(new_text, dest='en').text\n",
        "\n",
        "# Mengonversi teks yang telah diterjemahkan menjadi fitur TF-IDF\n",
        "translated_text_tfidf = tfidf_vectorizer.transform([translated_text])\n",
        "\n",
        "# Menampilkan prediksi sentimen\n",
        "predicted_sentiment = rf_classifier.predict(translated_text_tfidf)\n",
        "sentiment_probability = rf_classifier.predict_proba(translated_text_tfidf)[0, 1]\n",
        "\n",
        "threshold = 0.5  # Threshold bisa diatur sesuai kebutuhan\n",
        "sentiment = \"Positive\" if sentiment_probability > threshold else \"Negative\"\n",
        "\n",
        "# Print hasil prediksi\n",
        "print(\"\\nText:\", translated_text)\n",
        "print(\"Sentiment Probability:\", sentiment_probability)\n",
        "print(\"Sentiment:\", sentiment)\n"
      ]
    }
  ]
}